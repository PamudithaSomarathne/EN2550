{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EN2550_Assignment_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4FkHeuy761V6L5a3S6SDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PamudithaSomarathne/EN2550/blob/master/4%20Neural%20Network/EN2550_Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SCX8aGfelIv"
      },
      "source": [
        "# Download and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBdw18SFeFYe"
      },
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epkSmmPOKNmN",
        "outputId": "af279c50-754f-407e-9aeb-9e4abadbab73"
      },
      "source": [
        "# Download and categorize data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "K = len(np.unique(y_train))\n",
        "\n",
        "# Compute data parameters\n",
        "Ntr = x_train.shape[0]\n",
        "Nte = x_test.shape[0]\n",
        "Din = x_train[0].size\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train = x_train - mean_image\n",
        "x_test = x_test - mean_image\n",
        "\n",
        "# Convert labels from integers to binary\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=K)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=K)\n",
        "\n",
        "# Reshape data and convert to float32                       # Wasn't them converted when normalizing???\n",
        "x_train = x_train.reshape((Ntr,Din)).astype(np.float32)\n",
        "x_test = x_test.reshape((Nte,Din)).astype(np.float32)\n",
        "\n",
        "print(\"Training data size :\", x_train.shape, \"\\nTraining label size :\",\\\n",
        "      y_train.shape, \"\\nTest data size :\", x_test.shape, \"\\nTest label size :\",\\\n",
        "      y_test.shape)\n",
        "print(\"No of classes :\", K)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Training data size : (50000, 3072) \n",
            "Training label size : (50000, 10) \n",
            "Test data size : (10000, 3072) \n",
            "Test label size : (10000, 10)\n",
            "No of classes : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHIwrWv5eqUc"
      },
      "source": [
        "# Part 1: Linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "928dc8XJeTdj"
      },
      "source": [
        "def initialize_linear_weights(shape, epsilon=0.001):\n",
        "  W = np.random.randn(shape[0], shape[1])*epsilon\n",
        "  b = np.zeros((1,shape[1]))\n",
        "  return [W,b]\n",
        "\n",
        "def forward_prop_linear(x_data, weights):\n",
        "  return np.matmul(x_data, weights[0]) +\\\n",
        "    np.matmul(np.ones((x_data.shape[0],1)),weights[1])\n",
        "\n",
        "def mean_sum_of_squared_errors(y, y_hat):\n",
        "  diff = (y-y_hat).astype(np.float32)\n",
        "  return np.mean(np.sum(np.multiply(diff,diff),axis=1))\n",
        "\n",
        "def back_prop_linear(y_hat, y, x):\n",
        "  return [np.matmul(x.T,2*(y_hat-y))/x.shape[0],np.sum(2*(y_hat-y),axis=0)/x.shape[0]]\n",
        "\n",
        "def gradient_descent_linear(grads, weights, learning_rate=0.01):\n",
        "  weights[0] = weights[0]-learning_rate*grads[0]\n",
        "  weights[1] = weights[1]-learning_rate*grads[1]\n",
        "  return weights"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EFbtnSUfVxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a295dae5-c67e-4f29-ef3e-98e0b4bc9874"
      },
      "source": [
        "no_epochs = 300\n",
        "weights = initialize_linear_weights((x_train.shape[1],K))\n",
        "history = []\n",
        "\n",
        "print(\"Starting training for\", no_epochs, \"epochs\")\n",
        "for epo in range(1,no_epochs+1):\n",
        "  y_hat = forward_prop_linear(x_train,weights)\n",
        "  loss = mean_sum_of_squared_errors(y_train, y_hat)\n",
        "  grads = back_prop_linear(y_hat, y_train, x_train)\n",
        "  weights = gradient_descent_linear(grads, weights, 0.0170)\n",
        "  history.append(loss)\n",
        "  if not(epo%20): print(\"Epoch no.\", epo, \"| Training loss:\",loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training for 300 epochs\n",
            "Epoch no. 20 | Training loss: 0.8354275\n",
            "Epoch no. 40 | Training loss: 0.8064882\n",
            "Epoch no. 60 | Training loss: 0.7969733\n",
            "Epoch no. 80 | Training loss: 0.7926867\n",
            "Epoch no. 100 | Training loss: 0.7900993\n",
            "Epoch no. 120 | Training loss: 0.78822654\n",
            "Epoch no. 140 | Training loss: 0.7867447\n",
            "Epoch no. 160 | Training loss: 0.785518\n",
            "Epoch no. 180 | Training loss: 0.78447485\n",
            "Epoch no. 200 | Training loss: 0.7835702\n",
            "Epoch no. 220 | Training loss: 0.7827736\n",
            "Epoch no. 240 | Training loss: 0.78206295\n",
            "Epoch no. 260 | Training loss: 0.78142226\n",
            "Epoch no. 280 | Training loss: 0.78083915\n",
            "Epoch no. 300 | Training loss: 0.7803044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOXDstRmQD4V",
        "outputId": "5249268d-9651-4189-aa25-7269afcbd499"
      },
      "source": [
        "y_hat_test = forward_prop_linear(x_test,weights)\n",
        "print(\"Training set final mean loss:\", history[-1])\n",
        "print(\"Test set mean loss:\",mean_sum_of_squared_errors(y_test, y_hat_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set final mean loss: 0.7803044\n",
            "Test set mean loss: 0.78648776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLXFtAndKY_z"
      },
      "source": [
        "# Part 2: 2-layer neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdLr6jAvKrzG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMKj_zMHKsVh"
      },
      "source": [
        "# Part 3: Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYfb-vpoKxcK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iRrnbhcKyH2"
      },
      "source": [
        "# Part 4: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3UfyR1jRFvN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}