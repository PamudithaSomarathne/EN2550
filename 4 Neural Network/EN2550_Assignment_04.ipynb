{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EN2550_Assignment_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7zlNMOCEonfzbgUAvncSY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PamudithaSomarathne/EN2550/blob/master/4%20Neural%20Network/EN2550_Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SCX8aGfelIv"
      },
      "source": [
        "# Download and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBdw18SFeFYe"
      },
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epkSmmPOKNmN",
        "outputId": "4a126490-a301-4d56-ebe6-d71535faa424"
      },
      "source": [
        "# Download and categorize data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "K = len(np.unique(y_train))\n",
        "\n",
        "# Compute data parameters\n",
        "Ntr = x_train.shape[0]\n",
        "Nte = x_test.shape[0]\n",
        "Din = x_train[0].size\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train = x_train - mean_image\n",
        "x_test = x_test - mean_image\n",
        "\n",
        "# Convert labels from integers to binary\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=K)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=K)\n",
        "\n",
        "# Reshape data and convert to float32                       # Wasn't them converted when normalizing???\n",
        "x_train = x_train.reshape((Ntr,Din)).astype(np.float32)\n",
        "x_test = x_test.reshape((Nte,Din)).astype(np.float32)\n",
        "\n",
        "print(\"Training data size :\", x_train.shape, \"\\nTraining label size :\",\\\n",
        "      y_train.shape, \"\\nTest data size :\", x_test.shape, \"\\nTest label size :\",\\\n",
        "      y_test.shape)\n",
        "print(\"No of classes :\", K)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size : (50000, 3072) \n",
            "Training label size : (50000, 10) \n",
            "Test data size : (10000, 3072) \n",
            "Test label size : (10000, 10)\n",
            "No of classes : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHIwrWv5eqUc"
      },
      "source": [
        "# Part 1: Linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "928dc8XJeTdj"
      },
      "source": [
        "def initialize_linear_weights(shape, epsilon=0.001):\n",
        "  W = np.random.randn(shape[0], shape[1])*epsilon\n",
        "  b = np.zeros((1,shape[1]))\n",
        "  return [W,b]\n",
        "\n",
        "def forward_prop_linear(x_data, weights):\n",
        "  return np.matmul(x_data, weights[0]) +\\\n",
        "    np.matmul(np.ones((x_data.shape[0],1)),weights[1])\n",
        "\n",
        "def mean_sum_of_squared_errors(y, y_hat):\n",
        "  diff = (y-y_hat).astype(np.float32)\n",
        "  return np.mean(np.sum(np.multiply(diff,diff),axis=1))\n",
        "\n",
        "def back_prop_linear():\n",
        "  pass\n",
        "\n",
        "def gradient_descent_linear(grads, weights, learning_rate=0.01):\n",
        "  weights[0] = weights[0]-learning_rate*grads[0]\n",
        "  weights[1] = weights[1]-learning_rate*grads[1]\n",
        "  return weights"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EFbtnSUfVxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee00661d-82cd-4bcc-fa06-186678b59386"
      },
      "source": [
        "no_epochs = 300\n",
        "weights = initialize_linear_weights((x_train.shape[1],K))\n",
        "\n",
        "print(\"Starting training for\", no_epochs, \"epochs\")\n",
        "for epo in range(1,no_epochs+1):\n",
        "  y_hat = forward_prop_linear(x_train,weights)\n",
        "  loss = mean_sum_of_squared_errors(y_train, y_hat)\n",
        "  grads = back_prop_linear()\n",
        "  weights = gradient_descent_linear(grads, weights)\n",
        "  if not(epo%20): print(\"Epoch no\", epo, \"| Training loss:\",loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training for 30 epochs\n",
            "Epoch no 15 | Training loss: 1.0062298\n",
            "Epoch no 30 | Training loss: 1.0062298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLXFtAndKY_z"
      },
      "source": [
        "# Part 2: 2-layer neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdLr6jAvKrzG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMKj_zMHKsVh"
      },
      "source": [
        "# Part 3: Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYfb-vpoKxcK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iRrnbhcKyH2"
      },
      "source": [
        "# Part 4: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3UfyR1jRFvN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}